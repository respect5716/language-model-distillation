{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae1a15b",
   "metadata": {},
   "source": [
    "# CLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7543e",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f3c235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 12 21:58:18 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN RTX           On   | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 41%   22C    P8    16W / 280W |      1MiB / 24219MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c259698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import hydra\n",
    "import GPUtil \n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import AutoModel, AutoModelForMaskedLM, AutoTokenizer, AutoConfig\n",
    "from transformers import get_scheduler\n",
    "from transformers import BatchEncoding\n",
    "from transformers.data.data_collator import DataCollatorForWholeWordMask\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf679402",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize('../configs'):\n",
    "    config = hydra.compose('config.yaml', overrides=['working_dir=../', 'model.mlm=false', 'data.batch_size=16'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d2bd9",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6f9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, tokenizer, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = load_dataset('text', data_files=os.path.join('../data', 'kowiki.txt'))['train']\n",
    "        self.dataset.set_transform(lambda batch: transform(batch, self.tokenizer, 512))\n",
    "        self.dataset = self.dataset.train_test_split(test_size=0.01)\n",
    "        self.train_dataset, self.eval_dataset = self.dataset['train'], self.dataset['test']\n",
    "        \n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        batch = BatchEncoding(batch)\n",
    "        batch['attention_mask'] = batch.input_ids.ne(self.tokenizer.pad_token_id).float()\n",
    "        return batch\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def validation_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.eval_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "def transform(batch, tokenizer, max_length):\n",
    "    new_batch = []\n",
    "    for text in batch['text']:\n",
    "        text = slice_text(text)\n",
    "        new_batch.append(text)\n",
    "    \n",
    "    return tokenizer(new_batch, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "\n",
    "\n",
    "def slice_text(text, max_char_length=1024):\n",
    "    if len(text) > max_char_length:\n",
    "        idx = np.random.randint(low=0, high=len(text)-max_char_length)\n",
    "        text = text[idx : idx+max_char_length]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67acf1",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6084ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_layers(model: torch.nn.Module, indices: List[int]):\n",
    "    model.encoder.layer = nn.ModuleList([l for i, l in enumerate(model.encoder.layer) if i in indices])\n",
    "    return model\n",
    "\n",
    "def select_indices_from_embedding(embedding: torch.Tensor, num_features: int = 384, corr_threshold: float = 0.3):\n",
    "    corr = torch.corrcoef(embedding.transpose(-1, -2))\n",
    "    corr = corr - torch.eye(corr.size(0))\n",
    "    \n",
    "    removed_indices = []\n",
    "    for idx in range(corr.size(0)):\n",
    "        most_sim_idx = corr[idx].argmax()\n",
    "        if corr[idx][most_sim_idx] > corr_threshold and idx > most_sim_idx:\n",
    "            removed_indices.append(idx)\n",
    "            \n",
    "    norm = embedding.norm(dim=0)\n",
    "    norm_indices = (-norm).argsort()\n",
    "\n",
    "    indices = [int(i) for i in norm_indices if i not in removed_indices]\n",
    "    indices = indices[:num_features]\n",
    "    return indices\n",
    "\n",
    "def select_weight(weight, indices, dim):\n",
    "    if type(dim) == int:\n",
    "        indices = torch.tensor(indices)\n",
    "        return torch.index_select(weight, dim, indices.to(weight.device))\n",
    "    \n",
    "    else:\n",
    "        for d in dim:\n",
    "            weight = select_weight(weight, indices, d)\n",
    "        return weight\n",
    "    \n",
    "\n",
    "def select_embedding(embedding, indices):\n",
    "    embedding.weight.data = select_weight(embedding.weight.data, indices, dim=1)\n",
    "    embedding.embedding_dim = len(indices)\n",
    "    return embedding\n",
    "\n",
    "def select_layernorm(layernorm, indices):\n",
    "    layernorm.weight.data = select_weight(layernorm.weight.data, indices, dim=0)\n",
    "    layernorm.bias.data = select_weight(layernorm.bias.data, indices, dim=0)\n",
    "    layernorm.normalized_shape = (len(indices), )\n",
    "    return layernorm\n",
    "\n",
    "def select_linear(linear, indices, dims=[0, 1]):\n",
    "    linear.weight.data = select_weight(linear.weight.data, indices, dim=dims)\n",
    "    if 0 in dims:\n",
    "        linear.bias.data = select_weight(linear.bias.data, indices, dim=0)\n",
    "        \n",
    "    if 1 in dims:\n",
    "        linear.in_features = len(indices)\n",
    "    if 0 in dims:\n",
    "        linear.out_features = len(indices)\n",
    "    return linear\n",
    "\n",
    "def select_bert_embeddings(bert_embeddings, indices):\n",
    "    bert_embeddings.word_embeddings = select_embedding(bert_embeddings.word_embeddings, indices)\n",
    "    bert_embeddings.position_embeddings = select_embedding(bert_embeddings.position_embeddings, indices)\n",
    "    bert_embeddings.token_type_embeddings = select_embedding(bert_embeddings.token_type_embeddings, indices)\n",
    "    bert_embeddings.LayerNorm = select_layernorm(bert_embeddings.LayerNorm, indices)\n",
    "    return bert_embeddings\n",
    "\n",
    "\n",
    "def select_bert_layer(bert_layer, indices):\n",
    "    bert_layer.attention.self.all_head_size = len(indices)\n",
    "    bert_layer.attention.self.attention_head_size = len(indices) // bert_layer.attention.self.num_attention_heads\n",
    "    \n",
    "    bert_layer.attention.self.query = select_linear(bert_layer.attention.self.query, indices)\n",
    "    bert_layer.attention.self.key = select_linear(bert_layer.attention.self.key, indices)\n",
    "    bert_layer.attention.self.value = select_linear(bert_layer.attention.self.value, indices)\n",
    "    \n",
    "    bert_layer.attention.output.dense = select_linear(bert_layer.attention.output.dense, indices)\n",
    "    bert_layer.attention.output.LayerNorm = select_layernorm(bert_layer.attention.output.LayerNorm, indices)\n",
    "    \n",
    "    bert_layer.intermediate.dense = select_linear(bert_layer.intermediate.dense, indices, dims=[1])\n",
    "    bert_layer.output.dense = select_linear(bert_layer.output.dense, indices, dims=[0])\n",
    "    bert_layer.output.LayerNorm = select_layernorm(bert_layer.output.LayerNorm, indices)\n",
    "    return bert_layer\n",
    "\n",
    "def select_bert_pooler(bert_pooler, indices):\n",
    "    bert_pooler.dense = select_linear(bert_pooler.dense, indices)\n",
    "    return bert_pooler\n",
    "\n",
    "def select_bert_model(bert_model, layer_indices, weight_indices):\n",
    "    bert_model = select_layers(bert_model, layer_indices)\n",
    "    bert_model.embeddings = select_bert_embeddings(bert_model.embeddings, weight_indices)\n",
    "    bert_model.encoder.layer = nn.ModuleList([select_bert_layer(l, weight_indices) for l in bert_model.encoder.layer])\n",
    "    bert_model.pooler = select_bert_pooler(bert_model.pooler, weight_indices)\n",
    "    return bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ac1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_distill(model):\n",
    "    model.base_model.encoder.layer[0].attention.self.__class__._forward = bert_self_attention_forward\n",
    "    for layer in model.base_model.encoder.layer:\n",
    "        layer.attention.self.forward = layer.attention.self._forward\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "\n",
    "def bert_self_attention_forward(\n",
    "    self,\n",
    "    hidden_states,\n",
    "    attention_mask=None,\n",
    "    head_mask=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    past_key_value=None,\n",
    "    output_attentions=False,\n",
    "):\n",
    "    mixed_query_layer = self.query(hidden_states)\n",
    "    mixed_key_layer = self.key(hidden_states)\n",
    "    mixed_value_layer = self.value(hidden_states)\n",
    "    \n",
    "    query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "    key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "    value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "    \n",
    "    self.q = mixed_query_layer # (Batch, Seq, Dim)\n",
    "    self.k = mixed_key_layer # (Batch, Seq, Dim)\n",
    "    self.v = mixed_value_layer # (Batch, Seq, Dim)\n",
    "\n",
    "    if self.is_decoder:\n",
    "        past_key_value = (key_layer, value_layer)\n",
    "\n",
    "    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "\n",
    "    if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "        seq_length = hidden_states.size()[1]\n",
    "        position_ids_l = torch.arange(seq_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
    "        position_ids_r = torch.arange(seq_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
    "        distance = position_ids_l - position_ids_r\n",
    "        positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
    "        positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
    "\n",
    "        if self.position_embedding_type == \"relative_key\":\n",
    "            relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "            attention_scores = attention_scores + relative_position_scores\n",
    "        elif self.position_embedding_type == \"relative_key_query\":\n",
    "            relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "            relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
    "            attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
    "\n",
    "    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "    if attention_mask is not None:\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "\n",
    "    attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "    attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "    if head_mask is not None:\n",
    "        attention_probs = attention_probs * head_mask\n",
    "\n",
    "    context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "    context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "    new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "    context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "    outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "    if self.is_decoder:\n",
    "        outputs = outputs + (past_key_value,)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def get_qkvs(model):\n",
    "    attns = [l.attention.self for l in model.base_model.encoder.layer]\n",
    "    qkvs = [{'q': a.q, 'k': a.k, 'v': a.v} for a in attns]    \n",
    "    return qkvs\n",
    "\n",
    "def transpose_for_scores(h, num_heads):\n",
    "    batch_size, seq_length, dim = h.size()\n",
    "    head_size = dim // num_heads\n",
    "    h = h.view(batch_size, seq_length, num_heads, head_size)\n",
    "    return h.permute(0, 2, 1, 3) # (batch, num_heads, seq_length, head_size)\n",
    "\n",
    "\n",
    "def attention(h1, h2, num_heads, attention_mask=None):\n",
    "    assert h1.size() == h2.size()\n",
    "    head_size = h1.size(-1) // num_heads\n",
    "    h1 = transpose_for_scores(h1, num_heads) # (batch, num_heads, seq_length, head_size)\n",
    "    h2 = transpose_for_scores(h2, num_heads) # (batch, num_heads, seq_length, head_size)\n",
    "\n",
    "    attn = torch.matmul(h1, h2.transpose(-1, -2)) # (batch_size, num_heads, seq_length, seq_length)\n",
    "    attn = attn / math.sqrt(head_size)\n",
    "    if attention_mask is not None:\n",
    "        attention_mask = attention_mask[:, None, None, :]\n",
    "        attention_mask = (1 - attention_mask) * -10000.0\n",
    "        attn = attn + attention_mask\n",
    "\n",
    "    return attn\n",
    "\n",
    "\n",
    "def kl_div_loss(s, t, temperature=1.):\n",
    "    if len(s.size()) != 2:\n",
    "        s = s.view(-1, s.size(-1))\n",
    "        t = t.view(-1, t.size(-1))\n",
    "\n",
    "    s = F.log_softmax(s / temperature, dim=-1)\n",
    "    t = F.softmax(t / temperature, dim=-1)\n",
    "    return F.kl_div(s, t, reduction='batchmean')\n",
    "\n",
    "def minilm_loss(t, s, num_relation_heads, attention_mask=None):\n",
    "    attn_t = attention(t, t, num_relation_heads, attention_mask)\n",
    "    attn_s = attention(s, s, num_relation_heads, attention_mask)\n",
    "    loss = kl_div_loss(attn_s, attn_t)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb701bc",
   "metadata": {},
   "source": [
    "## 4. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610b6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb9355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-82324f4e586d6530\n",
      "Reusing dataset text (/root/.cache/huggingface/datasets/text/default-82324f4e586d6530/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c776539ad8a4e83904fcf9cfefbcd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_module = DataModule(tokenizer)\n",
    "data_module.setup()\n",
    "loader = iter(data_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a661444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511e1bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "teacher = AutoModel.from_pretrained('klue/bert-base', output_hidden_states=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e57900",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('klue/bert-base', num_hidden_layers=3, hidden_size=384)\n",
    "student = AutoModel.from_config(config)\n",
    "student = to_distill(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b5ee6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_outputs = teacher(**batch)\n",
    "student_outputs = student(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "372407b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_cls = teacher_outputs.last_hidden_state[:4, 0]\n",
    "student_cls = student_outputs.last_hidden_state[:4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5bfdd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_for_scores(h, num_heads):\n",
    "    batch_size, seq_length, dim = h.size()\n",
    "    head_size = dim // num_heads\n",
    "    h = h.view(batch_size, seq_length, num_heads, head_size)\n",
    "    return h.permute(0, 2, 1, 3) # (batch, num_heads, seq_length, head_size)\n",
    "\n",
    "\n",
    "def attention(h1, h2, num_heads, attention_mask=None):\n",
    "    assert h1.size() == h2.size()\n",
    "    head_size = h1.size(-1) // num_heads\n",
    "    h1 = transpose_for_scores(h1, num_heads) # (batch, num_heads, seq_length, head_size)\n",
    "    h2 = transpose_for_scores(h2, num_heads) # (batch, num_heads, seq_length, head_size)\n",
    "\n",
    "    attn = torch.matmul(h1, h2.transpose(-1, -2)) # (batch_size, num_heads, seq_length, seq_length)\n",
    "    attn = attn / math.sqrt(head_size)\n",
    "    if attention_mask is not None:\n",
    "        attention_mask = attention_mask[:, None, None, :]\n",
    "        attention_mask = (1 - attention_mask) * -10000.0\n",
    "        attn = attn + attention_mask\n",
    "\n",
    "    return attn\n",
    "\n",
    "\n",
    "def kl_div_loss(s, t, temperature):\n",
    "    if len(s.size()) != 2:\n",
    "        s = s.view(-1, s.size(-1))\n",
    "        t = t.view(-1, t.size(-1))\n",
    "\n",
    "    s = F.log_softmax(s / temperature, dim=-1)\n",
    "    t = F.softmax(t / temperature, dim=-1)\n",
    "    return F.kl_div(s, t, reduction='batchmean')\n",
    "\n",
    "\n",
    "def minilm_loss(t, s, num_relation_heads, attention_mask=None, temperature=1.0):\n",
    "    attn_t = attention(t, t, num_relation_heads, attention_mask)\n",
    "    attn_s = attention(s, s, num_relation_heads, attention_mask)\n",
    "    loss = kl_div_loss(attn_s, attn_t, temperature=temperature)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1bde7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_cls = teacher_cls.unsqueeze(0)\n",
    "student_cls = student_cls.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1212a52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2475, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minilm_loss(teacher_cls, student_cls, 48, None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61579810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4406, 0.1450, 0.3133, 0.1011],\n",
       "        [0.1187, 0.6125, 0.1160, 0.1528],\n",
       "        [0.2786, 0.1261, 0.4840, 0.1113],\n",
       "        [0.0363, 0.0671, 0.0450, 0.8516]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(teacher_cls, teacher_cls, 48).softmax(dim=-1)[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd208692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdist(e, squared=False, eps=1e-12):\n",
    "    e_square = e.pow(2).sum(dim=1)\n",
    "    prod = e @ e.t()\n",
    "    res = (e_square.unsqueeze(1) + e_square.unsqueeze(0) - 2 * prod).clamp(min=eps)\n",
    "\n",
    "    if not squared:\n",
    "        res = res.sqrt()\n",
    "\n",
    "    res = res.clone()\n",
    "    res[range(len(e)), range(len(e))] = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec98fb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 9.0273, 9.9646, 9.9388],\n",
       "        [9.0273, 0.0000, 9.6253, 8.2866],\n",
       "        [9.9646, 9.6253, 0.0000, 9.3097],\n",
       "        [9.9388, 8.2866, 9.3097, 0.0000]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdist(student_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646bcbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "114aadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = torch.cdist(teacher_cls, teacher_cls, p=2)\n",
    "sd = torch.cdist(student_cls, student_cls, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10d9e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_td = td[td>0].mean()\n",
    "td /= mean_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1aa05742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdist(v):\n",
    "    d = torch.cdist(v, v, p=2)\n",
    "    m = d[d>0].mean()\n",
    "    return d / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a9851fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = cdist(teacher_cls)\n",
    "sd = cdist(student_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a0d320f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0039, grad_fn=<SmoothL1LossBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.smooth_l1_loss(sd, td, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318f151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7467c320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 9.0273, 9.9646, 9.9388],\n",
       "        [9.0273, 0.0000, 9.6253, 8.2866],\n",
       "        [9.9646, 9.6253, 0.0000, 9.3097],\n",
       "        [9.9388, 8.2866, 9.3097, 0.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(student_cls, student_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "404ba993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2821, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_loss_fn(student_cls, teacher_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e71f1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_t = torch.cdist(t, t)\n",
    "dist_s = torch.cdist(s, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15d9dc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0263, 0.0257, 0.0248, 0.0221, 0.0256, 0.0277, 0.0276],\n",
       "        [0.0263, 0.0000, 0.0294, 0.0313, 0.0246, 0.0247, 0.0282, 0.0227],\n",
       "        [0.0257, 0.0294, 0.0000, 0.0257, 0.0260, 0.0276, 0.0308, 0.0331],\n",
       "        [0.0248, 0.0313, 0.0257, 0.0000, 0.0272, 0.0293, 0.0333, 0.0340],\n",
       "        [0.0221, 0.0246, 0.0260, 0.0272, 0.0000, 0.0257, 0.0277, 0.0268],\n",
       "        [0.0256, 0.0247, 0.0276, 0.0293, 0.0257, 0.0000, 0.0306, 0.0289],\n",
       "        [0.0277, 0.0282, 0.0308, 0.0333, 0.0277, 0.0306, 0.0000, 0.0321],\n",
       "        [0.0276, 0.0227, 0.0331, 0.0340, 0.0268, 0.0289, 0.0321, 0.0000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_t / t.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "facae465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0231, 0.0237, 0.0232, 0.0216, 0.0235, 0.0227, 0.0288],\n",
       "        [0.0231, 0.0000, 0.0218, 0.0209, 0.0211, 0.0210, 0.0211, 0.0265],\n",
       "        [0.0237, 0.0218, 0.0000, 0.0220, 0.0215, 0.0220, 0.0225, 0.0267],\n",
       "        [0.0232, 0.0209, 0.0220, 0.0000, 0.0203, 0.0220, 0.0222, 0.0272],\n",
       "        [0.0216, 0.0211, 0.0215, 0.0203, 0.0000, 0.0216, 0.0209, 0.0257],\n",
       "        [0.0235, 0.0210, 0.0220, 0.0220, 0.0216, 0.0000, 0.0226, 0.0277],\n",
       "        [0.0227, 0.0211, 0.0225, 0.0222, 0.0209, 0.0226, 0.0000, 0.0266],\n",
       "        [0.0288, 0.0265, 0.0267, 0.0272, 0.0257, 0.0277, 0.0266, 0.0000]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_s / s.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7f64fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_outputs = teacher(**batch)\n",
    "student_outputs = student(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a796b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_cls = teacher_outputs.last_hidden_state[:, 0, :]\n",
    "student_cls = student_outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "teacher_qkv = get_qkvs(teacher)[-1]# (batch, head, seq, head_dim)\n",
    "student_qkv = get_qkvs(student)[-1] # (batch, head, seq, head_dim)\n",
    "\n",
    "loss_q = distance_loss_fn(student_qkv['q'], teacher_qkv['q'])\n",
    "loss_k = distance_loss_fn(student_qkv['k'], teacher_qkv['k'])\n",
    "loss_v = distance_loss_fn(student_qkv['v'], teacher_qkv['v'])\n",
    "loss_cls = distance_loss_fn(student_cls, teacher_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d615534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.5106), tensor(8.9481), tensor(3.4897), tensor(0.9064))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_q, loss_k, loss_v, loss_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89a77172",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_cls = teacher_outputs.last_hidden_state[:, 0, :]\n",
    "student_cls = student_outputs.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cb89116f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, 23.8793, 24.8112, 23.0736, 21.2155, 22.8808, 22.5494, 22.5182],\n",
       "        [23.8793,  0.0000,  9.9119, 19.6570, 23.2631, 21.9032, 19.6912, 22.2391],\n",
       "        [24.8112,  9.9119,  0.0000, 20.7842, 23.0034, 22.7179, 20.4372, 23.2159],\n",
       "        [23.0736, 19.6570, 20.7842,  0.0000, 20.2961, 19.3592, 18.5026, 20.6066],\n",
       "        [21.2155, 23.2631, 23.0034, 20.2961,  0.0000, 23.4661, 24.1644, 22.4794],\n",
       "        [22.8808, 21.9032, 22.7179, 19.3592, 23.4661,  0.0000, 19.8730, 21.4704],\n",
       "        [22.5494, 19.6912, 20.4372, 18.5026, 24.1644, 19.8730,  0.0000, 20.0151],\n",
       "        [22.5182, 22.2391, 23.2159, 20.6066, 22.4794, 21.4704, 20.0151,  0.0000]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(teacher_cls, teacher_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bbb6697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_loss_fn(s, t):\n",
    "    dist_t = torch.cdist(t, t)\n",
    "    dist_s = torch.cdist(s, s)\n",
    "    return F.huber_loss(dist_s, dist_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f7b2d4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2299, grad_fn=<HuberLossBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_loss(teacher_cls, student_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a238a1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 512])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(teacher_qkvs[-1]['q'], teacher_qkvs[-1]['q']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "59cc1412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.0016)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_loss(teacher_qkvs[-1]['q'], student_qkvs[-1]['q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f601bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, 23.8793, 24.8112, 23.0736, 21.2155, 22.8808, 22.5494, 22.5182],\n",
       "        [23.8793,  0.0000,  9.9119, 19.6570, 23.2631, 21.9032, 19.6912, 22.2391],\n",
       "        [24.8112,  9.9119,  0.0000, 20.7842, 23.0034, 22.7179, 20.4372, 23.2159],\n",
       "        [23.0736, 19.6570, 20.7842,  0.0000, 20.2961, 19.3592, 18.5026, 20.6066],\n",
       "        [21.2155, 23.2631, 23.0034, 20.2961,  0.0000, 23.4661, 24.1644, 22.4794],\n",
       "        [22.8808, 21.9032, 22.7179, 19.3592, 23.4661,  0.0000, 19.8730, 21.4704],\n",
       "        [22.5494, 19.6912, 20.4372, 18.5026, 24.1644, 19.8730,  0.0000, 20.0151],\n",
       "        [22.5182, 22.2391, 23.2159, 20.6066, 22.4794, 21.4704, 20.0151,  0.0000]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_cls_dist = torch.cdist(teacher_cls, teacher_cls)\n",
    "student_cls_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c75fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_cls_sim = sim_matrix(teacher_cls, teacher_cls)\n",
    "student_cls_sim = sim_matrix(student_cls, student_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e7ee890",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_qkvs = get_qkvs(model)\n",
    "student_qkvs = get_qkvs(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc1265bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_dist = torch.cdist(teacher_qkvs[-1]['q'], teacher_qkvs[-1]['q'])\n",
    "student_dist = torch.cdist(student_qkvs[-1]['q'], student_qkvs[-1]['q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "114945a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.0016)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.huber_loss(student_dist, teacher_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afbadbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(59.7368)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(student_dist, teacher_dist) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a564b288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, 23.8793, 24.8112, 23.0736, 21.2155, 22.8808, 22.5494, 22.5182],\n",
       "        [23.8793,  0.0000,  9.9119, 19.6570, 23.2631, 21.9032, 19.6912, 22.2391],\n",
       "        [24.8112,  9.9119,  0.0000, 20.7842, 23.0034, 22.7179, 20.4372, 23.2159],\n",
       "        [23.0736, 19.6570, 20.7842,  0.0000, 20.2961, 19.3592, 18.5026, 20.6066],\n",
       "        [21.2155, 23.2631, 23.0034, 20.2961,  0.0000, 23.4661, 24.1644, 22.4794],\n",
       "        [22.8808, 21.9032, 22.7179, 19.3592, 23.4661,  0.0000, 19.8730, 21.4704],\n",
       "        [22.5494, 19.6912, 20.4372, 18.5026, 24.1644, 19.8730,  0.0000, 20.0151],\n",
       "        [22.5182, 22.2391, 23.2159, 20.6066, 22.4794, 21.4704, 20.0151,  0.0000]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(teacher_cls, teacher_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81c23163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.5393, 0.5030, 0.5679, 0.6387, 0.5788, 0.5872, 0.5904],\n",
       "        [0.5393, 1.0000, 0.9199, 0.6831, 0.5612, 0.6101, 0.6819, 0.5964],\n",
       "        [0.5030, 0.9199, 1.0000, 0.6461, 0.5713, 0.5809, 0.6577, 0.5605],\n",
       "        [0.5679, 0.6831, 0.6461, 1.0000, 0.6645, 0.6940, 0.7179, 0.6519],\n",
       "        [0.6387, 0.5612, 0.5713, 0.6645, 1.0000, 0.5554, 0.5243, 0.5904],\n",
       "        [0.5788, 0.6101, 0.5809, 0.6940, 0.5554, 1.0000, 0.6775, 0.6254],\n",
       "        [0.5872, 0.6819, 0.6577, 0.7179, 0.5243, 0.6775, 1.0000, 0.6715],\n",
       "        [0.5904, 0.5964, 0.5605, 0.6519, 0.5904, 0.6254, 0.6715, 1.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_cls_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b265b187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 이산화 셀레늄 ( 는 셀레늄과 산소로 이루어진 화합물이다. 화학식은 SeO2이다. 사슬 모양의 거대 분자이다. 상온에서는 백색의 흡습성 결정으로 존재한다. 액체는 등청색이며, 기체는 황록색이다. [UNK] 승화한다. 비중은 3. 954이다. 물, 에탄올, 아세트산에 잘 녹는다. 환원되기 쉬운 물질이다. 공기 중의 먼지에 의해서도 분해된다. 물에 녹일 경우 아셀렌산을 형성하며 녹는다. 셀레늄을 공기 또는 산소 중에서 연소시켜 얻을 수 있다. 이산화 셀레늄은 주로 다음과 같은 용도로 사용된다. 유기물의 합성에서 산화제나 촉매로 사용된다. 셀레늄 화합물 합성의 원료로 사용된다. 이산화 셀레늄은 독성이 있는 화합물이다. 만성적으로 접촉할 경우 창백함, 설태, 위장 질환, 신경쇠약 등을 일으킬 수 있다. 이산화 셀레늄과 같이 물에 녹을 수 있는 셀레늄 화합물은 독성이 강한데, 이는 물질이 체내의 설파이드릴 효소를 공격하기 때문인 것으로 추정된다 化 學 大 [UNK] 典 [UNK] 集 [UNK] 員 會 편, 성용길, 김창홍 역, 《 화학대사전 》, 서울 世 和, 2001. https : / / web. archive. org / web / 20080608083320 / http : / / www. jtbaker. com / msds / englishhtml / s1130. htm 분류 : 셀레늄 화합물 분류 : 산화물 분류 : 산성 산화물 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d85cb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.8776, 0.8585, 0.8832, 0.8530, 0.8797, 0.8698, 0.8731],\n",
       "        [0.8776, 1.0000, 0.8613, 0.8838, 0.8692, 0.8800, 0.8721, 0.8759],\n",
       "        [0.8585, 0.8613, 1.0000, 0.8597, 0.8437, 0.8624, 0.8521, 0.8508],\n",
       "        [0.8832, 0.8838, 0.8597, 1.0000, 0.8629, 0.8833, 0.8891, 0.8800],\n",
       "        [0.8530, 0.8692, 0.8437, 0.8629, 1.0000, 0.8797, 0.8810, 0.8672],\n",
       "        [0.8797, 0.8800, 0.8624, 0.8833, 0.8797, 1.0000, 0.8844, 0.8748],\n",
       "        [0.8698, 0.8721, 0.8521, 0.8891, 0.8810, 0.8844, 1.0000, 0.8748],\n",
       "        [0.8731, 0.8759, 0.8508, 0.8800, 0.8672, 0.8748, 0.8748, 1.0000]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_cls_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab4c77d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_982/3824031322.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_cls_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_embedding_loss\u001b[0;34m(input1, input2, target, margin, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3306\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "F.cosine_embedding_loss(student_cls, student_cls, target=teacher_cls_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2105ae32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(teacher_cls, teacher_cls, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ed69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
